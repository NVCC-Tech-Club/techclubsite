{"ast":null,"code":"import _defineProperty from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport _regeneratorRuntime from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _get from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/get.js\";\nimport _getPrototypeOf from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/getPrototypeOf.js\";\nimport _slicedToArray from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport _createForOfIteratorHelper from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper.js\";\nimport _classCallCheck from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"C:/Users/erden/OneDrive/Documents/GitHub/techclubsite/streamlit_calendar/frontend/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { __asyncValues, __awaiter } from \"tslib\";\nimport { Table } from '../table.mjs';\nimport { MAGIC } from './message.mjs';\nimport { Vector } from '../vector.mjs';\nimport { DataType } from '../type.mjs';\nimport { Message } from './metadata/message.mjs';\nimport * as metadata from './metadata/message.mjs';\nimport { FileBlock, Footer } from './metadata/file.mjs';\nimport { MessageHeader, MetadataVersion } from '../enum.mjs';\nimport { compareSchemas } from '../visitor/typecomparator.mjs';\nimport { AsyncByteQueue } from '../io/stream.mjs';\nimport { VectorAssembler } from '../visitor/vectorassembler.mjs';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler.mjs';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler.mjs';\nimport { toUint8Array } from '../util/buffer.mjs';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch.mjs';\nimport { ReadableInterop } from '../io/interfaces.mjs';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat.mjs';\nexport var RecordBatchWriter = /*#__PURE__*/function (_ReadableInterop, _Symbol$asyncIterator) {\n  _inherits(RecordBatchWriter, _ReadableInterop);\n  var _super = _createSuper(RecordBatchWriter);\n  function RecordBatchWriter(options) {\n    var _this;\n    _classCallCheck(this, RecordBatchWriter);\n    _this = _super.call(this);\n    _this._position = 0;\n    _this._started = false;\n    // @ts-ignore\n    _this._sink = new AsyncByteQueue();\n    _this._schema = null;\n    _this._dictionaryBlocks = [];\n    _this._recordBatchBlocks = [];\n    _this._dictionaryDeltaOffsets = new Map();\n    isObject(options) || (options = {\n      autoDestroy: true,\n      writeLegacyIpcFormat: false\n    });\n    _this._autoDestroy = typeof options.autoDestroy === 'boolean' ? options.autoDestroy : true;\n    _this._writeLegacyIpcFormat = typeof options.writeLegacyIpcFormat === 'boolean' ? options.writeLegacyIpcFormat : false;\n    return _this;\n  }\n  /** @nocollapse */\n  // @ts-ignore\n  _createClass(RecordBatchWriter, [{\n    key: \"toString\",\n    value: function toString() {\n      var sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return this._sink.toString(sync);\n    }\n  }, {\n    key: \"toUint8Array\",\n    value: function toUint8Array() {\n      var sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return this._sink.toUint8Array(sync);\n    }\n  }, {\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      var _this2 = this;\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return _this2.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(this, input);\n      }\n      return _writeAll(this, input);\n    }\n  }, {\n    key: \"closed\",\n    get: function get() {\n      return this._sink.closed;\n    }\n  }, {\n    key: _Symbol$asyncIterator,\n    value: function value() {\n      return this._sink[Symbol.asyncIterator]();\n    }\n  }, {\n    key: \"toDOMStream\",\n    value: function toDOMStream(options) {\n      return this._sink.toDOMStream(options);\n    }\n  }, {\n    key: \"toNodeStream\",\n    value: function toNodeStream(options) {\n      return this._sink.toNodeStream(options);\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      return this.reset()._sink.close();\n    }\n  }, {\n    key: \"abort\",\n    value: function abort(reason) {\n      return this.reset()._sink.abort(reason);\n    }\n  }, {\n    key: \"finish\",\n    value: function finish() {\n      this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n      return this;\n    }\n  }, {\n    key: \"reset\",\n    value: function reset() {\n      var sink = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._sink;\n      var schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n      if (sink === this._sink || sink instanceof AsyncByteQueue) {\n        this._sink = sink;\n      } else {\n        this._sink = new AsyncByteQueue();\n        if (sink && isWritableDOMStream(sink)) {\n          this.toDOMStream({\n            type: 'bytes'\n          }).pipeTo(sink);\n        } else if (sink && isWritableNodeStream(sink)) {\n          this.toNodeStream({\n            objectMode: false\n          }).pipe(sink);\n        }\n      }\n      if (this._started && this._schema) {\n        this._writeFooter(this._schema);\n      }\n      this._started = false;\n      this._dictionaryBlocks = [];\n      this._recordBatchBlocks = [];\n      this._dictionaryDeltaOffsets = new Map();\n      if (!schema || !compareSchemas(schema, this._schema)) {\n        if (schema == null) {\n          this._position = 0;\n          this._schema = null;\n        } else {\n          this._started = true;\n          this._schema = schema;\n          this._writeSchema(schema);\n        }\n      }\n      return this;\n    }\n  }, {\n    key: \"write\",\n    value: function write(payload) {\n      var schema = null;\n      if (!this._sink) {\n        throw new Error(\"RecordBatchWriter is closed\");\n      } else if (payload == null) {\n        return this.finish() && undefined;\n      } else if (payload instanceof Table && !(schema = payload.schema)) {\n        return this.finish() && undefined;\n      } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n        return this.finish() && undefined;\n      }\n      if (schema && !compareSchemas(schema, this._schema)) {\n        if (this._started && this._autoDestroy) {\n          return this.close();\n        }\n        this.reset(this._sink, schema);\n      }\n      if (payload instanceof RecordBatch) {\n        if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n          this._writeRecordBatch(payload);\n        }\n      } else if (payload instanceof Table) {\n        this.writeAll(payload.batches);\n      } else if (isIterable(payload)) {\n        this.writeAll(payload);\n      }\n    }\n  }, {\n    key: \"_writeMessage\",\n    value: function _writeMessage(message) {\n      var alignment = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n      var a = alignment - 1;\n      var buffer = Message.encode(message);\n      var flatbufferSize = buffer.byteLength;\n      var prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n      var alignedSize = flatbufferSize + prefixSize + a & ~a;\n      var nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n      if (message.headerType === MessageHeader.RecordBatch) {\n        this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n      } else if (message.headerType === MessageHeader.DictionaryBatch) {\n        this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n      }\n      // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n      if (!this._writeLegacyIpcFormat) {\n        this._write(Int32Array.of(-1));\n      }\n      // Write the flatbuffer size prefix including padding\n      this._write(Int32Array.of(alignedSize - prefixSize));\n      // Write the flatbuffer\n      if (flatbufferSize > 0) {\n        this._write(buffer);\n      }\n      // Write any padding\n      return this._writePadding(nPaddingBytes);\n    }\n  }, {\n    key: \"_write\",\n    value: function _write(chunk) {\n      if (this._started) {\n        var buffer = toUint8Array(chunk);\n        if (buffer && buffer.byteLength > 0) {\n          this._sink.write(buffer);\n          this._position += buffer.byteLength;\n        }\n      }\n      return this;\n    }\n  }, {\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._writeMessage(Message.from(schema));\n    }\n    // @ts-ignore\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      // eos bytes\n      return this._writeLegacyIpcFormat ? this._write(Int32Array.of(0)) : this._write(Int32Array.of(-1, 0));\n    }\n  }, {\n    key: \"_writeMagic\",\n    value: function _writeMagic() {\n      return this._write(MAGIC);\n    }\n  }, {\n    key: \"_writePadding\",\n    value: function _writePadding(nBytes) {\n      return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n  }, {\n    key: \"_writeRecordBatch\",\n    value: function _writeRecordBatch(batch) {\n      var _VectorAssembler$asse = VectorAssembler.assemble(batch),\n        byteLength = _VectorAssembler$asse.byteLength,\n        nodes = _VectorAssembler$asse.nodes,\n        bufferRegions = _VectorAssembler$asse.bufferRegions,\n        buffers = _VectorAssembler$asse.buffers;\n      var recordBatch = new metadata.RecordBatch(batch.numRows, nodes, bufferRegions);\n      var message = Message.from(recordBatch, byteLength);\n      return this._writeDictionaries(batch)._writeMessage(message)._writeBodyBuffers(buffers);\n    }\n  }, {\n    key: \"_writeDictionaryBatch\",\n    value: function _writeDictionaryBatch(dictionary, id) {\n      var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n      var _VectorAssembler$asse2 = VectorAssembler.assemble(new Vector([dictionary])),\n        byteLength = _VectorAssembler$asse2.byteLength,\n        nodes = _VectorAssembler$asse2.nodes,\n        bufferRegions = _VectorAssembler$asse2.bufferRegions,\n        buffers = _VectorAssembler$asse2.buffers;\n      var recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n      var dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n      var message = Message.from(dictionaryBatch, byteLength);\n      return this._writeMessage(message)._writeBodyBuffers(buffers);\n    }\n  }, {\n    key: \"_writeBodyBuffers\",\n    value: function _writeBodyBuffers(buffers) {\n      var buffer;\n      var size, padding;\n      for (var i = -1, n = buffers.length; ++i < n;) {\n        if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n          this._write(buffer);\n          if ((padding = (size + 7 & ~7) - size) > 0) {\n            this._writePadding(padding);\n          }\n        }\n      }\n      return this;\n    }\n  }, {\n    key: \"_writeDictionaries\",\n    value: function _writeDictionaries(batch) {\n      var _iterator = _createForOfIteratorHelper(batch.dictionaries),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var _step$value = _slicedToArray(_step.value, 2),\n            id = _step$value[0],\n            dictionary = _step$value[1];\n          var offset = this._dictionaryDeltaOffsets.get(id) || 0;\n          if (offset === 0 || (dictionary = dictionary === null || dictionary === void 0 ? void 0 : dictionary.slice(offset)).length > 0) {\n            var _iterator2 = _createForOfIteratorHelper(dictionary.data),\n              _step2;\n            try {\n              for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                var data = _step2.value;\n                this._writeDictionaryBatch(data, id, offset > 0);\n                offset += data.length;\n              }\n            } catch (err) {\n              _iterator2.e(err);\n            } finally {\n              _iterator2.f();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n      return this;\n    }\n  }], [{\n    key: \"throughNode\",\n    value: function throughNode(options) {\n      throw new Error(\"\\\"throughNode\\\" not available in this environment\");\n    }\n    /** @nocollapse */\n  }, {\n    key: \"throughDOM\",\n    value: function throughDOM(\n    // @ts-ignore\n    writableStrategy,\n    // @ts-ignore\n    readableStrategy) {\n      throw new Error(\"\\\"throughDOM\\\" not available in this environment\");\n    }\n  }]);\n  return RecordBatchWriter;\n}(ReadableInterop, Symbol.asyncIterator);\n/** @ignore */\nexport var RecordBatchStreamWriter = /*#__PURE__*/function (_RecordBatchWriter) {\n  _inherits(RecordBatchStreamWriter, _RecordBatchWriter);\n  var _super2 = _createSuper(RecordBatchStreamWriter);\n  function RecordBatchStreamWriter() {\n    _classCallCheck(this, RecordBatchStreamWriter);\n    return _super2.apply(this, arguments);\n  }\n  _createClass(RecordBatchStreamWriter, null, [{\n    key: \"writeAll\",\n    value: /** @nocollapse */\n    function writeAll(input, options) {\n      var writer = new RecordBatchStreamWriter(options);\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return writer.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(writer, input);\n      }\n      return _writeAll(writer, input);\n    }\n  }]);\n  return RecordBatchStreamWriter;\n}(RecordBatchWriter);\n/** @ignore */\nexport var RecordBatchFileWriter = /*#__PURE__*/function (_RecordBatchWriter2) {\n  _inherits(RecordBatchFileWriter, _RecordBatchWriter2);\n  var _super3 = _createSuper(RecordBatchFileWriter);\n  function RecordBatchFileWriter() {\n    var _this3;\n    _classCallCheck(this, RecordBatchFileWriter);\n    _this3 = _super3.call(this);\n    _this3._autoDestroy = true;\n    return _this3;\n  }\n  // @ts-ignore\n  _createClass(RecordBatchFileWriter, [{\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._writeMagic()._writePadding(2);\n    }\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      var buffer = Footer.encode(new Footer(schema, MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n      return _get(_getPrototypeOf(RecordBatchFileWriter.prototype), \"_writeFooter\", this).call(this, schema) // EOS bytes for sequential readers\n      ._write(buffer) // Write the flatbuffer\n      ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n      ._writeMagic(); // then the magic suffix\n    }\n  }], [{\n    key: \"writeAll\",\n    value: /** @nocollapse */\n    function writeAll(input) {\n      var writer = new RecordBatchFileWriter();\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return writer.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(writer, input);\n      }\n      return _writeAll(writer, input);\n    }\n  }]);\n  return RecordBatchFileWriter;\n}(RecordBatchWriter);\n/** @ignore */\nexport var RecordBatchJSONWriter = /*#__PURE__*/function (_RecordBatchWriter3) {\n  _inherits(RecordBatchJSONWriter, _RecordBatchWriter3);\n  var _super4 = _createSuper(RecordBatchJSONWriter);\n  function RecordBatchJSONWriter() {\n    var _this4;\n    _classCallCheck(this, RecordBatchJSONWriter);\n    _this4 = _super4.call(this);\n    _this4._autoDestroy = true;\n    _this4._recordBatches = [];\n    _this4._dictionaries = [];\n    return _this4;\n  }\n  /** @nocollapse */\n  _createClass(RecordBatchJSONWriter, [{\n    key: \"_writeMessage\",\n    value: function _writeMessage() {\n      return this;\n    }\n    // @ts-ignore\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      return this;\n    }\n  }, {\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._write(\"{\\n  \\\"schema\\\": \".concat(JSON.stringify({\n        fields: schema.fields.map(function (field) {\n          return fieldToJSON(field);\n        })\n      }, null, 2)));\n    }\n  }, {\n    key: \"_writeDictionaries\",\n    value: function _writeDictionaries(batch) {\n      if (batch.dictionaries.size > 0) {\n        this._dictionaries.push(batch);\n      }\n      return this;\n    }\n  }, {\n    key: \"_writeDictionaryBatch\",\n    value: function _writeDictionaryBatch(dictionary, id) {\n      var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n      this._write(this._dictionaryBlocks.length === 0 ? \"    \" : \",\\n    \");\n      this._write(\"\".concat(dictionaryBatchToJSON(dictionary, id, isDelta)));\n      this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n      return this;\n    }\n  }, {\n    key: \"_writeRecordBatch\",\n    value: function _writeRecordBatch(batch) {\n      this._writeDictionaries(batch);\n      this._recordBatches.push(batch);\n      return this;\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      if (this._dictionaries.length > 0) {\n        this._write(\",\\n  \\\"dictionaries\\\": [\\n\");\n        var _iterator3 = _createForOfIteratorHelper(this._dictionaries),\n          _step3;\n        try {\n          for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n            var batch = _step3.value;\n            _get(_getPrototypeOf(RecordBatchJSONWriter.prototype), \"_writeDictionaries\", this).call(this, batch);\n          }\n        } catch (err) {\n          _iterator3.e(err);\n        } finally {\n          _iterator3.f();\n        }\n        this._write(\"\\n  ]\");\n      }\n      if (this._recordBatches.length > 0) {\n        for (var i = -1, n = this._recordBatches.length; ++i < n;) {\n          this._write(i === 0 ? \",\\n  \\\"batches\\\": [\\n    \" : \",\\n    \");\n          this._write(\"\".concat(recordBatchToJSON(this._recordBatches[i])));\n          this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n        }\n        this._write(\"\\n  ]\");\n      }\n      if (this._schema) {\n        this._write(\"\\n}\");\n      }\n      this._dictionaries = [];\n      this._recordBatches = [];\n      return _get(_getPrototypeOf(RecordBatchJSONWriter.prototype), \"close\", this).call(this);\n    }\n  }], [{\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      return new RecordBatchJSONWriter().writeAll(input);\n    }\n  }]);\n  return RecordBatchJSONWriter;\n}(RecordBatchWriter);\n/** @ignore */\nfunction _writeAll(writer, input) {\n  var chunks = input;\n  if (input instanceof Table) {\n    chunks = input.batches;\n    writer.reset(undefined, input.schema);\n  }\n  var _iterator4 = _createForOfIteratorHelper(chunks),\n    _step4;\n  try {\n    for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n      var batch = _step4.value;\n      writer.write(batch);\n    }\n  } catch (err) {\n    _iterator4.e(err);\n  } finally {\n    _iterator4.f();\n  }\n  return writer.finish();\n}\n/** @ignore */\nfunction writeAllAsync(writer, batches) {\n  var batches_1, batches_1_1;\n  var e_1, _a;\n  return __awaiter(this, void 0, void 0, /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n    var batch;\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          _context.prev = 0;\n          batches_1 = __asyncValues(batches);\n        case 2:\n          _context.next = 4;\n          return batches_1.next();\n        case 4:\n          batches_1_1 = _context.sent;\n          if (batches_1_1.done) {\n            _context.next = 10;\n            break;\n          }\n          batch = batches_1_1.value;\n          writer.write(batch);\n        case 8:\n          _context.next = 2;\n          break;\n        case 10:\n          _context.next = 15;\n          break;\n        case 12:\n          _context.prev = 12;\n          _context.t0 = _context[\"catch\"](0);\n          e_1 = {\n            error: _context.t0\n          };\n        case 15:\n          _context.prev = 15;\n          _context.prev = 16;\n          if (!(batches_1_1 && !batches_1_1.done && (_a = batches_1.return))) {\n            _context.next = 20;\n            break;\n          }\n          _context.next = 20;\n          return _a.call(batches_1);\n        case 20:\n          _context.prev = 20;\n          if (!e_1) {\n            _context.next = 23;\n            break;\n          }\n          throw e_1.error;\n        case 23:\n          return _context.finish(20);\n        case 24:\n          return _context.finish(15);\n        case 25:\n          return _context.abrupt(\"return\", writer.finish());\n        case 26:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee, null, [[0, 12, 15, 25], [16,, 20, 24]]);\n  }));\n}\n/** @ignore */\nfunction fieldToJSON(_ref) {\n  var name = _ref.name,\n    type = _ref.type,\n    nullable = _ref.nullable;\n  var assembler = new JSONTypeAssembler();\n  return {\n    'name': name,\n    'nullable': nullable,\n    'type': assembler.visit(type),\n    'children': (type.children || []).map(function (field) {\n      return fieldToJSON(field);\n    }),\n    'dictionary': !DataType.isDictionary(type) ? undefined : {\n      'id': type.id,\n      'isOrdered': type.isOrdered,\n      'indexType': assembler.visit(type.indices)\n    }\n  };\n}\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary, id) {\n  var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  var _JSONVectorAssembler$ = JSONVectorAssembler.assemble(new RecordBatch(_defineProperty({}, id, dictionary))),\n    _JSONVectorAssembler$2 = _slicedToArray(_JSONVectorAssembler$, 1),\n    columns = _JSONVectorAssembler$2[0];\n  return JSON.stringify({\n    'id': id,\n    'isDelta': isDelta,\n    'data': {\n      'count': dictionary.length,\n      'columns': columns\n    }\n  }, null, 2);\n}\n/** @ignore */\nfunction recordBatchToJSON(records) {\n  var _JSONVectorAssembler$3 = JSONVectorAssembler.assemble(records),\n    _JSONVectorAssembler$4 = _slicedToArray(_JSONVectorAssembler$3, 1),\n    columns = _JSONVectorAssembler$4[0];\n  return JSON.stringify({\n    'count': records.numRows,\n    'columns': columns\n  }, null, 2);\n}","map":{"version":3,"names":["Table","MAGIC","Vector","DataType","Message","metadata","FileBlock","Footer","MessageHeader","MetadataVersion","compareSchemas","AsyncByteQueue","VectorAssembler","JSONTypeAssembler","JSONVectorAssembler","toUint8Array","RecordBatch","_InternalEmptyPlaceholderRecordBatch","ReadableInterop","isPromise","isAsyncIterable","isWritableDOMStream","isWritableNodeStream","isIterable","isObject","RecordBatchWriter","_ReadableInterop","_Symbol$asyncIterator","_inherits","_super","_createSuper","options","_this","_classCallCheck","call","_position","_started","_sink","_schema","_dictionaryBlocks","_recordBatchBlocks","_dictionaryDeltaOffsets","Map","autoDestroy","writeLegacyIpcFormat","_autoDestroy","_writeLegacyIpcFormat","_createClass","key","value","toString","sync","arguments","length","undefined","writeAll","input","_this2","then","x","writeAllAsync","get","closed","Symbol","asyncIterator","toDOMStream","toNodeStream","close","reset","abort","reason","finish","sink","schema","type","pipeTo","objectMode","pipe","_writeFooter","_writeSchema","write","payload","Error","_writeRecordBatch","batches","_writeMessage","message","alignment","a","buffer","encode","flatbufferSize","byteLength","prefixSize","alignedSize","nPaddingBytes","headerType","push","bodyLength","DictionaryBatch","_write","Int32Array","of","_writePadding","chunk","from","_writeMagic","nBytes","Uint8Array","batch","_VectorAssembler$asse","assemble","nodes","bufferRegions","buffers","recordBatch","numRows","_writeDictionaries","_writeBodyBuffers","_writeDictionaryBatch","dictionary","id","isDelta","set","_VectorAssembler$asse2","dictionaryBatch","size","padding","i","n","_iterator","_createForOfIteratorHelper","dictionaries","_step","s","done","_step$value","_slicedToArray","offset","slice","_iterator2","data","_step2","err","e","f","throughNode","throughDOM","writableStrategy","readableStrategy","RecordBatchStreamWriter","_RecordBatchWriter","_super2","apply","writer","RecordBatchFileWriter","_RecordBatchWriter2","_super3","_this3","V4","_get","_getPrototypeOf","prototype","RecordBatchJSONWriter","_RecordBatchWriter3","_super4","_this4","_recordBatches","_dictionaries","concat","JSON","stringify","fields","map","field","fieldToJSON","dictionaryBatchToJSON","_iterator3","_step3","recordBatchToJSON","chunks","_iterator4","_step4","batches_1","__asyncValues","_context","next","batches_1_1","sent","prev","t0","stop","_callee","_ref","name","nullable","assembler","visit","children","isDictionary","isOrdered","indices","_JSONVectorAssembler$","_defineProperty","_JSONVectorAssembler$2","columns","records","_JSONVectorAssembler$3","_JSONVectorAssembler$4"],"sources":["C:\\Users\\erden\\OneDrive\\Documents\\GitHub\\techclubsite\\streamlit_calendar\\frontend\\node_modules\\apache-arrow\\src\\ipc\\writer.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Data } from '../data.js';\nimport { Table } from '../table.js';\nimport { MAGIC } from './message.js';\nimport { Vector } from '../vector.js';\nimport { DataType, TypeMap } from '../type.js';\nimport { Schema, Field } from '../schema.js';\nimport { Message } from './metadata/message.js';\nimport * as metadata from './metadata/message.js';\nimport { FileBlock, Footer } from './metadata/file.js';\nimport { MessageHeader, MetadataVersion } from '../enum.js';\nimport { compareSchemas } from '../visitor/typecomparator.js';\nimport { WritableSink, AsyncByteQueue } from '../io/stream.js';\nimport { VectorAssembler } from '../visitor/vectorassembler.js';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler.js';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler.js';\nimport { ArrayBufferViewInput, toUint8Array } from '../util/buffer.js';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch.js';\nimport { Writable, ReadableInterop, ReadableDOMStreamOptions } from '../io/interfaces.js';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat.js';\n\nexport interface RecordBatchStreamWriterOptions {\n    /**\n     *\n     */\n    autoDestroy?: boolean;\n    /**\n     * A flag indicating whether the RecordBatchWriter should construct pre-0.15.0\n     * encapsulated IPC Messages, which reserves  4 bytes for the Message metadata\n     * length instead of 8.\n     * @see https://issues.apache.org/jira/browse/ARROW-6313\n     */\n    writeLegacyIpcFormat?: boolean;\n}\n\nexport class RecordBatchWriter<T extends TypeMap = any> extends ReadableInterop<Uint8Array> implements Writable<RecordBatch<T>> {\n\n    /** @nocollapse */\n    // @ts-ignore\n    public static throughNode(options?: import('stream').DuplexOptions & { autoDestroy: boolean }): import('stream').Duplex {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    public static throughDOM<T extends TypeMap>(\n        // @ts-ignore\n        writableStrategy?: QueuingStrategy<RecordBatch<T>> & { autoDestroy: boolean },\n        // @ts-ignore\n        readableStrategy?: { highWaterMark?: number; size?: any }\n    ): { writable: WritableStream<Table<T> | RecordBatch<T>>; readable: ReadableStream<Uint8Array> } {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n\n    constructor(options?: RecordBatchStreamWriterOptions) {\n        super();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n\n    protected _position = 0;\n    protected _started = false;\n    protected _autoDestroy: boolean;\n    protected _writeLegacyIpcFormat: boolean;\n    // @ts-ignore\n    protected _sink = new AsyncByteQueue();\n    protected _schema: Schema | null = null;\n    protected _dictionaryBlocks: FileBlock[] = [];\n    protected _recordBatchBlocks: FileBlock[] = [];\n    protected _dictionaryDeltaOffsets = new Map<number, number>();\n\n    public toString(sync: true): string;\n    public toString(sync?: false): Promise<string>;\n    public toString(sync: any = false) {\n        return this._sink.toString(sync) as Promise<string> | string;\n    }\n    public toUint8Array(sync: true): Uint8Array;\n    public toUint8Array(sync?: false): Promise<Uint8Array>;\n    public toUint8Array(sync: any = false) {\n        return this._sink.toUint8Array(sync) as Promise<Uint8Array> | Uint8Array;\n    }\n\n    public writeAll(input: Table<T> | Iterable<RecordBatch<T>>): this;\n    public writeAll(input: AsyncIterable<RecordBatch<T>>): Promise<this>;\n    public writeAll(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<any> | Table<T> | Iterable<RecordBatch<T>> | AsyncIterable<RecordBatch<T>>) {\n        if (isPromise<any>(input)) {\n            return input.then((x) => this.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, <any>input);\n    }\n\n    public get closed() { return this._sink.closed; }\n    public [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    public toDOMStream(options?: ReadableDOMStreamOptions) { return this._sink.toDOMStream(options); }\n    public toNodeStream(options?: import('stream').ReadableOptions) { return this._sink.toNodeStream(options); }\n\n    public close() {\n        return this.reset()._sink.close();\n    }\n    public abort(reason?: any) {\n        return this.reset()._sink.abort(reason);\n    }\n    public finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    public reset(sink: WritableSink<ArrayBufferViewInput> = this._sink, schema: Schema<T> | null = null) {\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink as AsyncByteQueue;\n        } else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            } else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n\n        if (!schema || !(compareSchemas(schema, this._schema))) {\n            if (schema == null) {\n                this._position = 0;\n                this._schema = null;\n            } else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n\n        return this;\n    }\n\n    public write(payload?: Table<T> | RecordBatch<T> | Iterable<RecordBatch<T>> | null) {\n        let schema: Schema<T> | null = null;\n\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        } else if (payload == null) {\n            return this.finish() && undefined;\n        } else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n\n        if (schema && !compareSchemas(schema, this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        } else if (payload instanceof Table) {\n            this.writeAll(payload.batches);\n        } else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n\n    protected _writeMessage<T extends MessageHeader>(message: Message<T>, alignment = 8) {\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        } else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) { this._write(buffer); }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n\n    protected _write(chunk: ArrayBufferViewInput) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMessage(Message.from(schema));\n    }\n\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n\n    protected _writeMagic() {\n        return this._write(MAGIC);\n    }\n\n    protected _writePadding(nBytes: number) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.numRows, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeDictionaryBatch(dictionary: Data, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(new Vector([dictionary]));\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeBodyBuffers(buffers: ArrayBufferView[]) {\n        let buffer: ArrayBufferView;\n        let size: number, padding: number;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary?.slice(offset)).length > 0) {\n                for (const data of dictionary.data) {\n                    this._writeDictionaryBatch(data, id, offset > 0);\n                    offset += data.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n\n/** @ignore */\nexport class RecordBatchStreamWriter<T extends TypeMap = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends TypeMap = any>(input: Table<T> | Iterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): RecordBatchStreamWriter<T>;\n    public static writeAll<T extends TypeMap = any>(input: AsyncIterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends TypeMap = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends TypeMap = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends TypeMap = any>(input: any, options?: RecordBatchStreamWriterOptions) {\n        const writer = new RecordBatchStreamWriter<T>(options);\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n\n/** @ignore */\nexport class RecordBatchFileWriter<T extends TypeMap = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends TypeMap = any>(input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchFileWriter<T>;\n    public static writeAll<T extends TypeMap = any>(input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends TypeMap = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends TypeMap = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends TypeMap = any>(input: any) {\n        const writer = new RecordBatchFileWriter<T>();\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n\n    // @ts-ignore\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMagic()._writePadding(2);\n    }\n\n    protected _writeFooter(schema: Schema<T>) {\n        const buffer = Footer.encode(new Footer(\n            schema, MetadataVersion.V4,\n            this._recordBatchBlocks, this._dictionaryBlocks\n        ));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n\n/** @ignore */\nexport class RecordBatchJSONWriter<T extends TypeMap = any> extends RecordBatchWriter<T> {\n\n    public static writeAll<T extends TypeMap = any>(this: typeof RecordBatchWriter, input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchJSONWriter<T>;\n    // @ts-ignore\n    public static writeAll<T extends TypeMap = any>(this: typeof RecordBatchWriter, input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends TypeMap = any>(this: typeof RecordBatchWriter, input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends TypeMap = any>(this: typeof RecordBatchWriter, input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends TypeMap = any>(this: typeof RecordBatchWriter, input: any) {\n        return new RecordBatchJSONWriter<T>().writeAll(input as any);\n    }\n\n    private _recordBatches: RecordBatch[];\n    private _dictionaries: RecordBatch[];\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n\n    protected _writeMessage() { return this; }\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) { return this; }\n    protected _writeSchema(schema: Schema<T>) {\n        return this._write(`{\\n  \"schema\": ${JSON.stringify({ fields: schema.fields.map(field => fieldToJSON(field)) }, null, 2)}`);\n    }\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    protected _writeDictionaryBatch(dictionary: Data, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    public close() {\n\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n\n        this._dictionaries = [];\n        this._recordBatches = [];\n\n        return super.close();\n    }\n}\n\n/** @ignore */\nfunction writeAll<T extends TypeMap = any>(writer: RecordBatchWriter<T>, input: Table<T> | Iterable<RecordBatch<T>>) {\n    let chunks = input as Iterable<RecordBatch<T>>;\n    if (input instanceof Table) {\n        chunks = input.batches;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nasync function writeAllAsync<T extends TypeMap = any>(writer: RecordBatchWriter<T>, batches: AsyncIterable<RecordBatch<T>>) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }: Field): Record<string, unknown> {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map((field: any) => fieldToJSON(field)),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary: Data, id: number, isDelta = false) {\n    const [columns] = JSONVectorAssembler.assemble(new RecordBatch({ [id]: dictionary }));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n\n/** @ignore */\nfunction recordBatchToJSON(records: RecordBatch) {\n    const [columns] = JSONVectorAssembler.assemble(records);\n    return JSON.stringify({\n        'count': records.numRows,\n        'columns': columns\n    }, null, 2);\n}\n"],"mappings":";;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA,SAASA,KAAK,QAAQ,cAAc;AACpC,SAASC,KAAK,QAAQ,eAAe;AACrC,SAASC,MAAM,QAAQ,eAAe;AACtC,SAASC,QAAQ,QAAiB,aAAa;AAE/C,SAASC,OAAO,QAAQ,wBAAwB;AAChD,OAAO,KAAKC,QAAQ,MAAM,wBAAwB;AAClD,SAASC,SAAS,EAAEC,MAAM,QAAQ,qBAAqB;AACvD,SAASC,aAAa,EAAEC,eAAe,QAAQ,aAAa;AAC5D,SAASC,cAAc,QAAQ,+BAA+B;AAC9D,SAAuBC,cAAc,QAAQ,kBAAkB;AAC/D,SAASC,eAAe,QAAQ,gCAAgC;AAChE,SAASC,iBAAiB,QAAQ,kCAAkC;AACpE,SAASC,mBAAmB,QAAQ,oCAAoC;AACxE,SAA+BC,YAAY,QAAQ,oBAAoB;AACvE,SAASC,WAAW,EAAEC,oCAAoC,QAAQ,oBAAoB;AACtF,SAAmBC,eAAe,QAAkC,sBAAsB;AAC1F,SAASC,SAAS,EAAEC,eAAe,EAAEC,mBAAmB,EAAEC,oBAAoB,EAAEC,UAAU,EAAEC,QAAQ,QAAQ,oBAAoB;AAgBhI,WAAaC,iBAA2C,0BAAAC,gBAAA,EAAAC,qBAAA;EAAAC,SAAA,CAAAH,iBAAA,EAAAC,gBAAA;EAAA,IAAAG,MAAA,GAAAC,YAAA,CAAAL,iBAAA;EAiBpD,SAAAA,kBAAYM,OAAwC;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAR,iBAAA;IAChDO,KAAA,GAAAH,MAAA,CAAAK,IAAA;IAMMF,KAAA,CAAAG,SAAS,GAAG,CAAC;IACbH,KAAA,CAAAI,QAAQ,GAAG,KAAK;IAG1B;IACUJ,KAAA,CAAAK,KAAK,GAAG,IAAI1B,cAAc,EAAE;IAC5BqB,KAAA,CAAAM,OAAO,GAAkB,IAAI;IAC7BN,KAAA,CAAAO,iBAAiB,GAAgB,EAAE;IACnCP,KAAA,CAAAQ,kBAAkB,GAAgB,EAAE;IACpCR,KAAA,CAAAS,uBAAuB,GAAG,IAAIC,GAAG,EAAkB;IAdzDlB,QAAQ,CAACO,OAAO,CAAC,KAAKA,OAAO,GAAG;MAAEY,WAAW,EAAE,IAAI;MAAEC,oBAAoB,EAAE;IAAK,CAAE,CAAC;IACnFZ,KAAA,CAAKa,YAAY,GAAI,OAAOd,OAAO,CAACY,WAAW,KAAK,SAAS,GAAIZ,OAAO,CAACY,WAAW,GAAG,IAAI;IAC3FX,KAAA,CAAKc,qBAAqB,GAAI,OAAOf,OAAO,CAACa,oBAAoB,KAAK,SAAS,GAAIb,OAAO,CAACa,oBAAoB,GAAG,KAAK;IAAC,OAAAZ,KAAA;EAC5H;EApBA;EACA;EAAAe,YAAA,CAAAtB,iBAAA;IAAAuB,GAAA;IAAAC,KAAA,EAkCO,SAAAC,SAAA,EAA0B;MAAA,IAAjBC,IAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAY,KAAK;MAC7B,OAAO,IAAI,CAACf,KAAK,CAACa,QAAQ,CAACC,IAAI,CAA6B;IAChE;EAAC;IAAAH,GAAA;IAAAC,KAAA,EAGM,SAAAlC,aAAA,EAA8B;MAAA,IAAjBoC,IAAA,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAY,KAAK;MACjC,OAAO,IAAI,CAACf,KAAK,CAACtB,YAAY,CAACoC,IAAI,CAAqC;IAC5E;EAAC;IAAAH,GAAA;IAAAC,KAAA,EAMM,SAAAM,SAASC,KAA6F;MAAA,IAAAC,MAAA;MACzG,IAAItC,SAAS,CAAMqC,KAAK,CAAC,EAAE;QACvB,OAAOA,KAAK,CAACE,IAAI,CAAC,UAACC,CAAC;UAAA,OAAKF,MAAI,CAACF,QAAQ,CAACI,CAAC,CAAC;QAAA,EAAC;OAC7C,MAAM,IAAIvC,eAAe,CAAiBoC,KAAK,CAAC,EAAE;QAC/C,OAAOI,aAAa,CAAC,IAAI,EAAEJ,KAAK,CAAC;;MAErC,OAAOD,SAAQ,CAAC,IAAI,EAAOC,KAAK,CAAC;IACrC;EAAC;IAAAR,GAAA;IAAAa,GAAA,EAED,SAAAA,IAAA,EAAiB;MAAK,OAAO,IAAI,CAACxB,KAAK,CAACyB,MAAM;IAAE;EAAC;IAAAd,GAAA,EAAArB,qBAAA;IAAAsB,KAAA,EAC1C,SAAAA,MAAA,EAAsB;MAAK,OAAO,IAAI,CAACZ,KAAK,CAAC0B,MAAM,CAACC,aAAa,CAAC,EAAE;IAAE;EAAC;IAAAhB,GAAA;IAAAC,KAAA,EACvE,SAAAgB,YAAYlC,OAAkC;MAAI,OAAO,IAAI,CAACM,KAAK,CAAC4B,WAAW,CAAClC,OAAO,CAAC;IAAE;EAAC;IAAAiB,GAAA;IAAAC,KAAA,EAC3F,SAAAiB,aAAanC,OAA0C;MAAI,OAAO,IAAI,CAACM,KAAK,CAAC6B,YAAY,CAACnC,OAAO,CAAC;IAAE;EAAC;IAAAiB,GAAA;IAAAC,KAAA,EAErG,SAAAkB,MAAA,EAAK;MACR,OAAO,IAAI,CAACC,KAAK,EAAE,CAAC/B,KAAK,CAAC8B,KAAK,EAAE;IACrC;EAAC;IAAAnB,GAAA;IAAAC,KAAA,EACM,SAAAoB,MAAMC,MAAY;MACrB,OAAO,IAAI,CAACF,KAAK,EAAE,CAAC/B,KAAK,CAACgC,KAAK,CAACC,MAAM,CAAC;IAC3C;EAAC;IAAAtB,GAAA;IAAAC,KAAA,EACM,SAAAsB,OAAA,EAAM;MACT,IAAI,CAAC1B,YAAY,GAAG,IAAI,CAACsB,KAAK,EAAE,GAAG,IAAI,CAACC,KAAK,CAAC,IAAI,CAAC/B,KAAK,EAAE,IAAI,CAACC,OAAO,CAAC;MACvE,OAAO,IAAI;IACf;EAAC;IAAAU,GAAA;IAAAC,KAAA,EACM,SAAAmB,MAAA,EAA4F;MAAA,IAAtFI,IAAA,GAAApB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA2C,IAAI,CAACf,KAAK;MAAA,IAAEoC,MAAA,GAAArB,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAA2B,IAAI;MAC/F,IAAKoB,IAAI,KAAK,IAAI,CAACnC,KAAK,IAAMmC,IAAI,YAAY7D,cAAe,EAAE;QAC3D,IAAI,CAAC0B,KAAK,GAAGmC,IAAsB;OACtC,MAAM;QACH,IAAI,CAACnC,KAAK,GAAG,IAAI1B,cAAc,EAAE;QACjC,IAAI6D,IAAI,IAAInD,mBAAmB,CAACmD,IAAI,CAAC,EAAE;UACnC,IAAI,CAACP,WAAW,CAAC;YAAES,IAAI,EAAE;UAAO,CAAE,CAAC,CAACC,MAAM,CAACH,IAAI,CAAC;SACnD,MAAM,IAAIA,IAAI,IAAIlD,oBAAoB,CAACkD,IAAI,CAAC,EAAE;UAC3C,IAAI,CAACN,YAAY,CAAC;YAAEU,UAAU,EAAE;UAAK,CAAE,CAAC,CAACC,IAAI,CAACL,IAAI,CAAC;;;MAI3D,IAAI,IAAI,CAACpC,QAAQ,IAAI,IAAI,CAACE,OAAO,EAAE;QAC/B,IAAI,CAACwC,YAAY,CAAC,IAAI,CAACxC,OAAO,CAAC;;MAGnC,IAAI,CAACF,QAAQ,GAAG,KAAK;MACrB,IAAI,CAACG,iBAAiB,GAAG,EAAE;MAC3B,IAAI,CAACC,kBAAkB,GAAG,EAAE;MAC5B,IAAI,CAACC,uBAAuB,GAAG,IAAIC,GAAG,EAAE;MAExC,IAAI,CAAC+B,MAAM,IAAI,CAAE/D,cAAc,CAAC+D,MAAM,EAAE,IAAI,CAACnC,OAAO,CAAE,EAAE;QACpD,IAAImC,MAAM,IAAI,IAAI,EAAE;UAChB,IAAI,CAACtC,SAAS,GAAG,CAAC;UAClB,IAAI,CAACG,OAAO,GAAG,IAAI;SACtB,MAAM;UACH,IAAI,CAACF,QAAQ,GAAG,IAAI;UACpB,IAAI,CAACE,OAAO,GAAGmC,MAAM;UACrB,IAAI,CAACM,YAAY,CAACN,MAAM,CAAC;;;MAIjC,OAAO,IAAI;IACf;EAAC;IAAAzB,GAAA;IAAAC,KAAA,EAEM,SAAA+B,MAAMC,OAAqE;MAC9E,IAAIR,MAAM,GAAqB,IAAI;MAEnC,IAAI,CAAC,IAAI,CAACpC,KAAK,EAAE;QACb,MAAM,IAAI6C,KAAK,8BAA8B,CAAC;OACjD,MAAM,IAAID,OAAO,IAAI,IAAI,EAAE;QACxB,OAAO,IAAI,CAACV,MAAM,EAAE,IAAIjB,SAAS;OACpC,MAAM,IAAI2B,OAAO,YAAYjF,KAAK,IAAI,EAAEyE,MAAM,GAAGQ,OAAO,CAACR,MAAM,CAAC,EAAE;QAC/D,OAAO,IAAI,CAACF,MAAM,EAAE,IAAIjB,SAAS;OACpC,MAAM,IAAI2B,OAAO,YAAYjE,WAAW,IAAI,EAAEyD,MAAM,GAAGQ,OAAO,CAACR,MAAM,CAAC,EAAE;QACrE,OAAO,IAAI,CAACF,MAAM,EAAE,IAAIjB,SAAS;;MAGrC,IAAImB,MAAM,IAAI,CAAC/D,cAAc,CAAC+D,MAAM,EAAE,IAAI,CAACnC,OAAO,CAAC,EAAE;QACjD,IAAI,IAAI,CAACF,QAAQ,IAAI,IAAI,CAACS,YAAY,EAAE;UACpC,OAAO,IAAI,CAACsB,KAAK,EAAE;;QAEvB,IAAI,CAACC,KAAK,CAAC,IAAI,CAAC/B,KAAK,EAAEoC,MAAM,CAAC;;MAGlC,IAAIQ,OAAO,YAAYjE,WAAW,EAAE;QAChC,IAAI,EAAEiE,OAAO,YAAYhE,oCAAoC,CAAC,EAAE;UAC5D,IAAI,CAACkE,iBAAiB,CAACF,OAAO,CAAC;;OAEtC,MAAM,IAAIA,OAAO,YAAYjF,KAAK,EAAE;QACjC,IAAI,CAACuD,QAAQ,CAAC0B,OAAO,CAACG,OAAO,CAAC;OACjC,MAAM,IAAI7D,UAAU,CAAC0D,OAAO,CAAC,EAAE;QAC5B,IAAI,CAAC1B,QAAQ,CAAC0B,OAAO,CAAC;;IAE9B;EAAC;IAAAjC,GAAA;IAAAC,KAAA,EAES,SAAAoC,cAAuCC,OAAmB,EAAe;MAAA,IAAbC,SAAS,GAAAnC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC;MAC/E,IAAMoC,CAAC,GAAGD,SAAS,GAAG,CAAC;MACvB,IAAME,MAAM,GAAGrF,OAAO,CAACsF,MAAM,CAACJ,OAAO,CAAC;MACtC,IAAMK,cAAc,GAAGF,MAAM,CAACG,UAAU;MACxC,IAAMC,UAAU,GAAG,CAAC,IAAI,CAAC/C,qBAAqB,GAAG,CAAC,GAAG,CAAC;MACtD,IAAMgD,WAAW,GAAIH,cAAc,GAAGE,UAAU,GAAGL,CAAC,GAAI,CAACA,CAAC;MAC1D,IAAMO,aAAa,GAAGD,WAAW,GAAGH,cAAc,GAAGE,UAAU;MAE/D,IAAIP,OAAO,CAACU,UAAU,KAAKxF,aAAa,CAACQ,WAAW,EAAE;QAClD,IAAI,CAACwB,kBAAkB,CAACyD,IAAI,CAAC,IAAI3F,SAAS,CAACwF,WAAW,EAAER,OAAO,CAACY,UAAU,EAAE,IAAI,CAAC/D,SAAS,CAAC,CAAC;OAC/F,MAAM,IAAImD,OAAO,CAACU,UAAU,KAAKxF,aAAa,CAAC2F,eAAe,EAAE;QAC7D,IAAI,CAAC5D,iBAAiB,CAAC0D,IAAI,CAAC,IAAI3F,SAAS,CAACwF,WAAW,EAAER,OAAO,CAACY,UAAU,EAAE,IAAI,CAAC/D,SAAS,CAAC,CAAC;;MAG/F;MACA,IAAI,CAAC,IAAI,CAACW,qBAAqB,EAAE;QAC7B,IAAI,CAACsD,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;;MAElC;MACA,IAAI,CAACF,MAAM,CAACC,UAAU,CAACC,EAAE,CAACR,WAAW,GAAGD,UAAU,CAAC,CAAC;MACpD;MACA,IAAIF,cAAc,GAAG,CAAC,EAAE;QAAE,IAAI,CAACS,MAAM,CAACX,MAAM,CAAC;;MAC7C;MACA,OAAO,IAAI,CAACc,aAAa,CAACR,aAAa,CAAC;IAC5C;EAAC;IAAA/C,GAAA;IAAAC,KAAA,EAES,SAAAmD,OAAOI,KAA2B;MACxC,IAAI,IAAI,CAACpE,QAAQ,EAAE;QACf,IAAMqD,MAAM,GAAG1E,YAAY,CAACyF,KAAK,CAAC;QAClC,IAAIf,MAAM,IAAIA,MAAM,CAACG,UAAU,GAAG,CAAC,EAAE;UACjC,IAAI,CAACvD,KAAK,CAAC2C,KAAK,CAACS,MAAM,CAAC;UACxB,IAAI,CAACtD,SAAS,IAAIsD,MAAM,CAACG,UAAU;;;MAG3C,OAAO,IAAI;IACf;EAAC;IAAA5C,GAAA;IAAAC,KAAA,EAES,SAAA8B,aAAaN,MAAiB;MACpC,OAAO,IAAI,CAACY,aAAa,CAACjF,OAAO,CAACqG,IAAI,CAAChC,MAAM,CAAC,CAAC;IACnD;IAEA;EAAA;IAAAzB,GAAA;IAAAC,KAAA,EACU,SAAA6B,aAAaL,MAAiB;MACpC;MACA,OAAO,IAAI,CAAC3B,qBAAqB,GAC3B,IAAI,CAACsD,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,CAAC,GAC7B,IAAI,CAACF,MAAM,CAACC,UAAU,CAACC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAC3C;EAAC;IAAAtD,GAAA;IAAAC,KAAA,EAES,SAAAyD,YAAA,EAAW;MACjB,OAAO,IAAI,CAACN,MAAM,CAACnG,KAAK,CAAC;IAC7B;EAAC;IAAA+C,GAAA;IAAAC,KAAA,EAES,SAAAsD,cAAcI,MAAc;MAClC,OAAOA,MAAM,GAAG,CAAC,GAAG,IAAI,CAACP,MAAM,CAAC,IAAIQ,UAAU,CAACD,MAAM,CAAC,CAAC,GAAG,IAAI;IAClE;EAAC;IAAA3D,GAAA;IAAAC,KAAA,EAES,SAAAkC,kBAAkB0B,KAAqB;MAC7C,IAAAC,qBAAA,GAAsDlG,eAAe,CAACmG,QAAQ,CAACF,KAAK,CAAC;QAA7EjB,UAAU,GAAAkB,qBAAA,CAAVlB,UAAU;QAAEoB,KAAK,GAAAF,qBAAA,CAALE,KAAK;QAAEC,aAAa,GAAAH,qBAAA,CAAbG,aAAa;QAAEC,OAAO,GAAAJ,qBAAA,CAAPI,OAAO;MACjD,IAAMC,WAAW,GAAG,IAAI9G,QAAQ,CAACW,WAAW,CAAC6F,KAAK,CAACO,OAAO,EAAEJ,KAAK,EAAEC,aAAa,CAAC;MACjF,IAAM3B,OAAO,GAAGlF,OAAO,CAACqG,IAAI,CAACU,WAAW,EAAEvB,UAAU,CAAC;MACrD,OAAO,IAAI,CACNyB,kBAAkB,CAACR,KAAK,CAAC,CACzBxB,aAAa,CAACC,OAAO,CAAC,CACtBgC,iBAAiB,CAACJ,OAAO,CAAC;IACnC;EAAC;IAAAlE,GAAA;IAAAC,KAAA,EAES,SAAAsE,sBAAsBC,UAAgB,EAAEC,EAAU,EAAiB;MAAA,IAAfC,OAAO,GAAAtE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;MACzE,IAAI,CAACX,uBAAuB,CAACkF,GAAG,CAACF,EAAE,EAAED,UAAU,CAACnE,MAAM,IAAI,IAAI,CAACZ,uBAAuB,CAACoB,GAAG,CAAC4D,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC;MACrG,IAAAG,sBAAA,GAAsDhH,eAAe,CAACmG,QAAQ,CAAC,IAAI7G,MAAM,CAAC,CAACsH,UAAU,CAAC,CAAC,CAAC;QAAhG5B,UAAU,GAAAgC,sBAAA,CAAVhC,UAAU;QAAEoB,KAAK,GAAAY,sBAAA,CAALZ,KAAK;QAAEC,aAAa,GAAAW,sBAAA,CAAbX,aAAa;QAAEC,OAAO,GAAAU,sBAAA,CAAPV,OAAO;MACjD,IAAMC,WAAW,GAAG,IAAI9G,QAAQ,CAACW,WAAW,CAACwG,UAAU,CAACnE,MAAM,EAAE2D,KAAK,EAAEC,aAAa,CAAC;MACrF,IAAMY,eAAe,GAAG,IAAIxH,QAAQ,CAAC8F,eAAe,CAACgB,WAAW,EAAEM,EAAE,EAAEC,OAAO,CAAC;MAC9E,IAAMpC,OAAO,GAAGlF,OAAO,CAACqG,IAAI,CAACoB,eAAe,EAAEjC,UAAU,CAAC;MACzD,OAAO,IAAI,CACNP,aAAa,CAACC,OAAO,CAAC,CACtBgC,iBAAiB,CAACJ,OAAO,CAAC;IACnC;EAAC;IAAAlE,GAAA;IAAAC,KAAA,EAES,SAAAqE,kBAAkBJ,OAA0B;MAClD,IAAIzB,MAAuB;MAC3B,IAAIqC,IAAY,EAAEC,OAAe;MACjC,KAAK,IAAIC,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAGf,OAAO,CAAC7D,MAAM,EAAE,EAAE2E,CAAC,GAAGC,CAAC,GAAG;QAC3C,IAAI,CAACxC,MAAM,GAAGyB,OAAO,CAACc,CAAC,CAAC,KAAK,CAACF,IAAI,GAAGrC,MAAM,CAACG,UAAU,IAAI,CAAC,EAAE;UACzD,IAAI,CAACQ,MAAM,CAACX,MAAM,CAAC;UACnB,IAAI,CAACsC,OAAO,GAAG,CAAED,IAAI,GAAG,CAAC,GAAI,CAAC,CAAC,IAAIA,IAAI,IAAI,CAAC,EAAE;YAC1C,IAAI,CAACvB,aAAa,CAACwB,OAAO,CAAC;;;;MAIvC,OAAO,IAAI;IACf;EAAC;IAAA/E,GAAA;IAAAC,KAAA,EAES,SAAAoE,mBAAmBR,KAAqB;MAAA,IAAAqB,SAAA,GAAAC,0BAAA,CACjBtB,KAAK,CAACuB,YAAY;QAAAC,KAAA;MAAA;QAA/C,KAAAH,SAAA,CAAAI,CAAA,MAAAD,KAAA,GAAAH,SAAA,CAAAD,CAAA,IAAAM,IAAA,GAAiD;UAAA,IAAAC,WAAA,GAAAC,cAAA,CAAAJ,KAAA,CAAApF,KAAA;YAAvCwE,EAAE,GAAAe,WAAA;YAAEhB,UAAU,GAAAgB,WAAA;UACpB,IAAIE,MAAM,GAAG,IAAI,CAACjG,uBAAuB,CAACoB,GAAG,CAAC4D,EAAE,CAAC,IAAI,CAAC;UACtD,IAAIiB,MAAM,KAAK,CAAC,IAAI,CAAClB,UAAU,GAAGA,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEmB,KAAK,CAACD,MAAM,CAAC,EAAErF,MAAM,GAAG,CAAC,EAAE;YAAA,IAAAuF,UAAA,GAAAT,0BAAA,CAClDX,UAAU,CAACqB,IAAI;cAAAC,MAAA;YAAA;cAAlC,KAAAF,UAAA,CAAAN,CAAA,MAAAQ,MAAA,GAAAF,UAAA,CAAAX,CAAA,IAAAM,IAAA,GAAoC;gBAAA,IAAzBM,IAAI,GAAAC,MAAA,CAAA7F,KAAA;gBACX,IAAI,CAACsE,qBAAqB,CAACsB,IAAI,EAAEpB,EAAE,EAAEiB,MAAM,GAAG,CAAC,CAAC;gBAChDA,MAAM,IAAIG,IAAI,CAACxF,MAAM;;YACxB,SAAA0F,GAAA;cAAAH,UAAA,CAAAI,CAAA,CAAAD,GAAA;YAAA;cAAAH,UAAA,CAAAK,CAAA;YAAA;;;MAER,SAAAF,GAAA;QAAAb,SAAA,CAAAc,CAAA,CAAAD,GAAA;MAAA;QAAAb,SAAA,CAAAe,CAAA;MAAA;MACD,OAAO,IAAI;IACf;EAAC;IAAAjG,GAAA;IAAAC,KAAA,EA/OM,SAAAiG,YAAmBnH,OAAmE;MACzF,MAAM,IAAImD,KAAK,oDAAkD,CAAC;IACtE;IACA;EAAA;IAAAlC,GAAA;IAAAC,KAAA,EACO,SAAAkG;IACH;IACAC,gBAA6E;IAC7E;IACAC,gBAAyD;MAEzD,MAAM,IAAInE,KAAK,mDAAiD,CAAC;IACrE;EAAC;EAAA,OAAAzD,iBAAA;AAAA,EAf2DP,eAA2B,EA4D/E6C,MAAM,CAACC,aAAa;AA0LhC;AACA,WAAasF,uBAAiD,0BAAAC,kBAAA;EAAA3H,SAAA,CAAA0H,uBAAA,EAAAC,kBAAA;EAAA,IAAAC,OAAA,GAAA1H,YAAA,CAAAwH,uBAAA;EAAA,SAAAA,wBAAA;IAAArH,eAAA,OAAAqH,uBAAA;IAAA,OAAAE,OAAA,CAAAC,KAAA,OAAArG,SAAA;EAAA;EAAAL,YAAA,CAAAuG,uBAAA;IAAAtG,GAAA;IAAAC,KAAA,EAK1D;IACO,SAAAM,SAAyCC,KAAU,EAAEzB,OAAwC;MAChG,IAAM2H,MAAM,GAAG,IAAIJ,uBAAuB,CAAIvH,OAAO,CAAC;MACtD,IAAIZ,SAAS,CAAMqC,KAAK,CAAC,EAAE;QACvB,OAAOA,KAAK,CAACE,IAAI,CAAC,UAACC,CAAC;UAAA,OAAK+F,MAAM,CAACnG,QAAQ,CAACI,CAAC,CAAC;QAAA,EAAC;OAC/C,MAAM,IAAIvC,eAAe,CAAiBoC,KAAK,CAAC,EAAE;QAC/C,OAAOI,aAAa,CAAC8F,MAAM,EAAElG,KAAK,CAAC;;MAEvC,OAAOD,SAAQ,CAACmG,MAAM,EAAElG,KAAK,CAAC;IAClC;EAAC;EAAA,OAAA8F,uBAAA;AAAA,EAdiE7H,iBAAoB;AAiB1F;AACA,WAAakI,qBAA+C,0BAAAC,mBAAA;EAAAhI,SAAA,CAAA+H,qBAAA,EAAAC,mBAAA;EAAA,IAAAC,OAAA,GAAA/H,YAAA,CAAA6H,qBAAA;EAgBxD,SAAAA,sBAAA;IAAA,IAAAG,MAAA;IAAA7H,eAAA,OAAA0H,qBAAA;IACIG,MAAA,GAAAD,OAAA,CAAA3H,IAAA;IACA4H,MAAA,CAAKjH,YAAY,GAAG,IAAI;IAAC,OAAAiH,MAAA;EAC7B;EAEA;EAAA/G,YAAA,CAAA4G,qBAAA;IAAA3G,GAAA;IAAAC,KAAA,EACU,SAAA8B,aAAaN,MAAiB;MACpC,OAAO,IAAI,CAACiC,WAAW,EAAE,CAACH,aAAa,CAAC,CAAC,CAAC;IAC9C;EAAC;IAAAvD,GAAA;IAAAC,KAAA,EAES,SAAA6B,aAAaL,MAAiB;MACpC,IAAMgB,MAAM,GAAGlF,MAAM,CAACmF,MAAM,CAAC,IAAInF,MAAM,CACnCkE,MAAM,EAAEhE,eAAe,CAACsJ,EAAE,EAC1B,IAAI,CAACvH,kBAAkB,EAAE,IAAI,CAACD,iBAAiB,CAClD,CAAC;MACF,OAAOyH,IAAA,CAAAC,eAAA,CAAAN,qBAAA,CAAAO,SAAA,yBAAAhI,IAAA,OACWuC,MAAM,EAAE;MAAA,CACrB2B,MAAM,CAACX,MAAM,CAAC,CAAC;MAAA,CACfW,MAAM,CAACC,UAAU,CAACC,EAAE,CAACb,MAAM,CAACG,UAAU,CAAC,CAAC,CAAC;MAAA,CACzCc,WAAW,EAAE,CAAC,CAAC;IACxB;EAAC;IAAA1D,GAAA;IAAAC,KAAA,EA/BD;IACO,SAAAM,SAAyCC,KAAU;MACtD,IAAMkG,MAAM,GAAG,IAAIC,qBAAqB,EAAK;MAC7C,IAAIxI,SAAS,CAAMqC,KAAK,CAAC,EAAE;QACvB,OAAOA,KAAK,CAACE,IAAI,CAAC,UAACC,CAAC;UAAA,OAAK+F,MAAM,CAACnG,QAAQ,CAACI,CAAC,CAAC;QAAA,EAAC;OAC/C,MAAM,IAAIvC,eAAe,CAAiBoC,KAAK,CAAC,EAAE;QAC/C,OAAOI,aAAa,CAAC8F,MAAM,EAAElG,KAAK,CAAC;;MAEvC,OAAOD,SAAQ,CAACmG,MAAM,EAAElG,KAAK,CAAC;IAClC;EAAC;EAAA,OAAAmG,qBAAA;AAAA,EAd+DlI,iBAAoB;AAuCxF;AACA,WAAa0I,qBAA+C,0BAAAC,mBAAA;EAAAxI,SAAA,CAAAuI,qBAAA,EAAAC,mBAAA;EAAA,IAAAC,OAAA,GAAAvI,YAAA,CAAAqI,qBAAA;EAexD,SAAAA,sBAAA;IAAA,IAAAG,MAAA;IAAArI,eAAA,OAAAkI,qBAAA;IACIG,MAAA,GAAAD,OAAA,CAAAnI,IAAA;IACAoI,MAAA,CAAKzH,YAAY,GAAG,IAAI;IACxByH,MAAA,CAAKC,cAAc,GAAG,EAAE;IACxBD,MAAA,CAAKE,aAAa,GAAG,EAAE;IAAC,OAAAF,MAAA;EAC5B;EAbA;EAAAvH,YAAA,CAAAoH,qBAAA;IAAAnH,GAAA;IAAAC,KAAA,EAeU,SAAAoC,cAAA,EAAa;MAAK,OAAO,IAAI;IAAE;IACzC;EAAA;IAAArC,GAAA;IAAAC,KAAA,EACU,SAAA6B,aAAaL,MAAiB;MAAI,OAAO,IAAI;IAAE;EAAC;IAAAzB,GAAA;IAAAC,KAAA,EAChD,SAAA8B,aAAaN,MAAiB;MACpC,OAAO,IAAI,CAAC2B,MAAM,qBAAAqE,MAAA,CAAmBC,IAAI,CAACC,SAAS,CAAC;QAAEC,MAAM,EAAEnG,MAAM,CAACmG,MAAM,CAACC,GAAG,CAAC,UAAAC,KAAK;UAAA,OAAIC,WAAW,CAACD,KAAK,CAAC;QAAA;MAAC,CAAE,EAAE,IAAI,EAAE,CAAC,CAAC,CAAE,CAAC;IAC/H;EAAC;IAAA9H,GAAA;IAAAC,KAAA,EACS,SAAAoE,mBAAmBR,KAAqB;MAC9C,IAAIA,KAAK,CAACuB,YAAY,CAACN,IAAI,GAAG,CAAC,EAAE;QAC7B,IAAI,CAAC0C,aAAa,CAACvE,IAAI,CAACY,KAAK,CAAC;;MAElC,OAAO,IAAI;IACf;EAAC;IAAA7D,GAAA;IAAAC,KAAA,EACS,SAAAsE,sBAAsBC,UAAgB,EAAEC,EAAU,EAAiB;MAAA,IAAfC,OAAO,GAAAtE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;MACzE,IAAI,CAACX,uBAAuB,CAACkF,GAAG,CAACF,EAAE,EAAED,UAAU,CAACnE,MAAM,IAAI,IAAI,CAACZ,uBAAuB,CAACoB,GAAG,CAAC4D,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC;MACrG,IAAI,CAACrB,MAAM,CAAC,IAAI,CAAC7D,iBAAiB,CAACc,MAAM,KAAK,CAAC,qBAAqB,CAAC;MACrE,IAAI,CAAC+C,MAAM,IAAAqE,MAAA,CAAIO,qBAAqB,CAACxD,UAAU,EAAEC,EAAE,EAAEC,OAAO,CAAC,CAAE,CAAC;MAChE,IAAI,CAACnF,iBAAiB,CAAC0D,IAAI,CAAC,IAAI3F,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;MACnD,OAAO,IAAI;IACf;EAAC;IAAA0C,GAAA;IAAAC,KAAA,EACS,SAAAkC,kBAAkB0B,KAAqB;MAC7C,IAAI,CAACQ,kBAAkB,CAACR,KAAK,CAAC;MAC9B,IAAI,CAAC0D,cAAc,CAACtE,IAAI,CAACY,KAAK,CAAC;MAC/B,OAAO,IAAI;IACf;EAAC;IAAA7D,GAAA;IAAAC,KAAA,EACM,SAAAkB,MAAA,EAAK;MAER,IAAI,IAAI,CAACqG,aAAa,CAACnH,MAAM,GAAG,CAAC,EAAE;QAC/B,IAAI,CAAC+C,MAAM,6BAA2B,CAAC;QAAC,IAAA6E,UAAA,GAAA9C,0BAAA,CACpB,IAAI,CAACqC,aAAa;UAAAU,MAAA;QAAA;UAAtC,KAAAD,UAAA,CAAA3C,CAAA,MAAA4C,MAAA,GAAAD,UAAA,CAAAhD,CAAA,IAAAM,IAAA,GAAwC;YAAA,IAA7B1B,KAAK,GAAAqE,MAAA,CAAAjI,KAAA;YACZ+G,IAAA,CAAAC,eAAA,CAAAE,qBAAA,CAAAD,SAAA,+BAAAhI,IAAA,OAAyB2E,KAAK;;QACjC,SAAAkC,GAAA;UAAAkC,UAAA,CAAAjC,CAAA,CAAAD,GAAA;QAAA;UAAAkC,UAAA,CAAAhC,CAAA;QAAA;QACD,IAAI,CAAC7C,MAAM,QAAQ,CAAC;;MAGxB,IAAI,IAAI,CAACmE,cAAc,CAAClH,MAAM,GAAG,CAAC,EAAE;QAChC,KAAK,IAAI2E,CAAC,GAAG,CAAC,CAAC,EAAEC,CAAC,GAAG,IAAI,CAACsC,cAAc,CAAClH,MAAM,EAAE,EAAE2E,CAAC,GAAGC,CAAC,GAAG;UACvD,IAAI,CAAC7B,MAAM,CAAC4B,CAAC,KAAK,CAAC,0CAAwC,CAAC;UAC5D,IAAI,CAAC5B,MAAM,IAAAqE,MAAA,CAAIU,iBAAiB,CAAC,IAAI,CAACZ,cAAc,CAACvC,CAAC,CAAC,CAAC,CAAE,CAAC;UAC3D,IAAI,CAACxF,kBAAkB,CAACyD,IAAI,CAAC,IAAI3F,SAAS,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;;QAExD,IAAI,CAAC8F,MAAM,QAAQ,CAAC;;MAGxB,IAAI,IAAI,CAAC9D,OAAO,EAAE;QACd,IAAI,CAAC8D,MAAM,MAAM,CAAC;;MAGtB,IAAI,CAACoE,aAAa,GAAG,EAAE;MACvB,IAAI,CAACD,cAAc,GAAG,EAAE;MAExB,OAAAP,IAAA,CAAAC,eAAA,CAAAE,qBAAA,CAAAD,SAAA,kBAAAhI,IAAA;IACJ;EAAC;IAAAc,GAAA;IAAAC,KAAA,EAjEM,SAAAM,SAAyEC,KAAU;MACtF,OAAO,IAAI2G,qBAAqB,EAAK,CAAC5G,QAAQ,CAACC,KAAY,CAAC;IAChE;EAAC;EAAA,OAAA2G,qBAAA;AAAA,EAV+D1I,iBAAoB;AA4ExF;AACA,SAAS8B,SAAQA,CAA0BmG,MAA4B,EAAElG,KAA0C;EAC/G,IAAI4H,MAAM,GAAG5H,KAAiC;EAC9C,IAAIA,KAAK,YAAYxD,KAAK,EAAE;IACxBoL,MAAM,GAAG5H,KAAK,CAAC4B,OAAO;IACtBsE,MAAM,CAACtF,KAAK,CAACd,SAAS,EAAEE,KAAK,CAACiB,MAAM,CAAC;;EACxC,IAAA4G,UAAA,GAAAlD,0BAAA,CACmBiD,MAAM;IAAAE,MAAA;EAAA;IAA1B,KAAAD,UAAA,CAAA/C,CAAA,MAAAgD,MAAA,GAAAD,UAAA,CAAApD,CAAA,IAAAM,IAAA,GAA4B;MAAA,IAAjB1B,KAAK,GAAAyE,MAAA,CAAArI,KAAA;MACZyG,MAAM,CAAC1E,KAAK,CAAC6B,KAAK,CAAC;;EACtB,SAAAkC,GAAA;IAAAsC,UAAA,CAAArC,CAAA,CAAAD,GAAA;EAAA;IAAAsC,UAAA,CAAApC,CAAA;EAAA;EACD,OAAOS,MAAM,CAACnF,MAAM,EAAE;AAC1B;AAEA;AACA,SAAeX,aAAaA,CAA0B8F,MAA4B,EAAEtE,OAAsC;;;;;;;;;UAC5FmG,SAAA,GAAAC,aAAA,CAAApG,OAAO;QAAA;UAAAqG,QAAA,CAAAC,IAAA;UAAA,OAAAH,SAAA,CAAAG,IAAA;QAAA;UAAAC,WAAA,GAAAF,QAAA,CAAAG,IAAA;UAAA,IAAAD,WAAA,CAAApD,IAAA;YAAAkD,QAAA,CAAAC,IAAA;YAAA;UAAA;UAAhB7E,KAAK,GAAA8E,WAAA,CAAA1I,KAAA;UAClByG,MAAM,CAAC1E,KAAK,CAAC6B,KAAK,CAAC;QAAC;UAAA4E,QAAA,CAAAC,IAAA;UAAA;QAAA;UAAAD,QAAA,CAAAC,IAAA;UAAA;QAAA;UAAAD,QAAA,CAAAI,IAAA;UAAAJ,QAAA,CAAAK,EAAA,GAAAL,QAAA;;;;;;;;;;;;;;;;;;;;;;;;;2CAEjB/B,MAAM,CAACnF,MAAM,EAAE;QAAA;QAAA;UAAA,OAAAkH,QAAA,CAAAM,IAAA;MAAA;IAAA,GAAAC,OAAA;EAAA,C;;AAG1B;AACA,SAASjB,WAAWA,CAAAkB,IAAA,EAAgC;EAAA,IAA7BC,IAAI,GAAAD,IAAA,CAAJC,IAAI;IAAExH,IAAI,GAAAuH,IAAA,CAAJvH,IAAI;IAAEyH,QAAQ,GAAAF,IAAA,CAARE,QAAQ;EACvC,IAAMC,SAAS,GAAG,IAAIvL,iBAAiB,EAAE;EACzC,OAAO;IACH,MAAM,EAAEqL,IAAI;IAAE,UAAU,EAAEC,QAAQ;IAClC,MAAM,EAAEC,SAAS,CAACC,KAAK,CAAC3H,IAAI,CAAC;IAC7B,UAAU,EAAE,CAACA,IAAI,CAAC4H,QAAQ,IAAI,EAAE,EAAEzB,GAAG,CAAC,UAACC,KAAU;MAAA,OAAKC,WAAW,CAACD,KAAK,CAAC;IAAA,EAAC;IACzE,YAAY,EAAE,CAAC3K,QAAQ,CAACoM,YAAY,CAAC7H,IAAI,CAAC,GAAGpB,SAAS,GAAG;MACrD,IAAI,EAAEoB,IAAI,CAAC+C,EAAE;MACb,WAAW,EAAE/C,IAAI,CAAC8H,SAAS;MAC3B,WAAW,EAAEJ,SAAS,CAACC,KAAK,CAAC3H,IAAI,CAAC+H,OAAO;;GAEhD;AACL;AAEA;AACA,SAASzB,qBAAqBA,CAACxD,UAAgB,EAAEC,EAAU,EAAiB;EAAA,IAAfC,OAAO,GAAAtE,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EACxE,IAAAsJ,qBAAA,GAAkB5L,mBAAmB,CAACiG,QAAQ,CAAC,IAAI/F,WAAW,CAAA2L,eAAA,KAAIlF,EAAE,EAAGD,UAAU,CAAE,CAAC,CAAC;IAAAoF,sBAAA,GAAAnE,cAAA,CAAAiE,qBAAA;IAA9EG,OAAO,GAAAD,sBAAA;EACd,OAAOlC,IAAI,CAACC,SAAS,CAAC;IAClB,IAAI,EAAElD,EAAE;IACR,SAAS,EAAEC,OAAO;IAClB,MAAM,EAAE;MACJ,OAAO,EAAEF,UAAU,CAACnE,MAAM;MAC1B,SAAS,EAAEwJ;;GAElB,EAAE,IAAI,EAAE,CAAC,CAAC;AACf;AAEA;AACA,SAAS1B,iBAAiBA,CAAC2B,OAAoB;EAC3C,IAAAC,sBAAA,GAAkBjM,mBAAmB,CAACiG,QAAQ,CAAC+F,OAAO,CAAC;IAAAE,sBAAA,GAAAvE,cAAA,CAAAsE,sBAAA;IAAhDF,OAAO,GAAAG,sBAAA;EACd,OAAOtC,IAAI,CAACC,SAAS,CAAC;IAClB,OAAO,EAAEmC,OAAO,CAAC1F,OAAO;IACxB,SAAS,EAAEyF;GACd,EAAE,IAAI,EAAE,CAAC,CAAC;AACf"},"metadata":{},"sourceType":"module","externalDependencies":[]}